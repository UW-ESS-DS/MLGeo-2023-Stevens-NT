{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "This homework will explore linear regression and resampling techniques by analysing data from a database of glaciers. The database is *Glatilda* for [*Glacier Ice Thickness Database*](!https://www.gtn-g.ch/data_catalogue_glathida/).\n",
    "\n",
    "1. Data prep (5 points)\n",
    "2. Mapping (10 points)\n",
    "3. Correlations between parameters (5 points)\n",
    "4. Linear regression and resampling techniques (10 points)\n",
    "\n",
    "## 1. Data Prep (5 points total)\n",
    "\n",
    "### a) Download data (1 point) \n",
    "The database is saved on a GitLab repository that you may clone: https://gitlab.com/wgms/glathida.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'glathida'...\n",
      "remote: Enumerating objects: 964, done.\u001b[K\n",
      "remote: Counting objects: 100% (431/431), done.\u001b[K\n",
      "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
      "remote: Total 964 (delta 232), reused 350 (delta 189), pack-reused 533\u001b[K\n",
      "Receiving objects: 100% (964/964), 245.07 MiB | 12.91 MiB/s, done.\n",
      "Resolving deltas: 100% (543/543), done.\n"
     ]
    }
   ],
   "source": [
    "# answer - NTS: ! at start of line pushes the script segment to CLI, rather than Python kernel\n",
    "!git clone https://gitlab.com/wgms/glathida.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Import Python modules (1 point) \n",
    "Import pandas, geopandas, plotting, raster files,  numpy, netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 16 from C header, got 96 from PyObject\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import netCDF4 as cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Read data (2 points)\n",
    "Read the glacier data from the file ``glathida/data/glacier.csv`` into a pandas data frame, and decribe briefly the dataframe content and its first few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      survey_id                   name external_db   external_id  latitude  \\\n",
      "id                                                                           \n",
      "1             1       Isfallsglaciären         WGI  SE4B000E0006  67.91500   \n",
      "2             1         Rabots glaciär         WGI  SE4B000E1016  67.91000   \n",
      "3             1          Storglaciären         WGI  SE4B000E0005  67.90000   \n",
      "4             2  South Cascade Glacier         WGI  US2M00264006  48.35698   \n",
      "5             3      Athabasca Glacier         FOG             7  52.17540   \n",
      "...         ...                    ...         ...           ...       ...   \n",
      "6627        254            Mount Adams         NaN           NaN  46.20240   \n",
      "6628        255            Mount Adams         NaN           NaN  46.20240   \n",
      "6629        256            Mount Adams         NaN           NaN  46.20398   \n",
      "6630        128           Mullwitzkees         AGI          6054  47.08670   \n",
      "6631        128           Mullwitzkees         AGI          6054  47.08670   \n",
      "\n",
      "      longitude        date    max_date    area  mean_slope  mean_thickness  \\\n",
      "id                                                                            \n",
      "1      18.56800  1979-03-01  1979-03-31   1.300         NaN            72.0   \n",
      "2      18.49600  1979-03-01  1979-03-31   4.100         NaN            84.0   \n",
      "3      18.57000  1979-03-01  1979-03-31   3.100         NaN            99.0   \n",
      "4    -121.05735  1975-01-01  1975-12-31   2.000         NaN            99.0   \n",
      "5    -117.28400         NaN         NaN   3.800         NaN           150.0   \n",
      "...         ...         ...         ...     ...         ...             ...   \n",
      "6627 -121.49090  1935-01-01  1935-12-31     NaN         NaN             NaN   \n",
      "6628 -121.49090  2002-05-01  2002-05-31  16.200         NaN            57.0   \n",
      "6629 -121.49376  2006-07-01  2006-07-31     NaN         NaN             NaN   \n",
      "6630   12.38000  1998-01-01  1998-12-31   3.229         NaN            39.0   \n",
      "6631   12.38000  2003-01-01  2003-12-31     NaN         NaN             NaN   \n",
      "\n",
      "      mean_thickness_uncertainty  max_thickness  max_thickness_uncertainty  \\\n",
      "id                                                                           \n",
      "1                            NaN          220.0                        NaN   \n",
      "2                            NaN          175.0                        NaN   \n",
      "3                            NaN          250.0                        NaN   \n",
      "4                            NaN          195.0                        NaN   \n",
      "5                            NaN            NaN                        NaN   \n",
      "...                          ...            ...                        ...   \n",
      "6627                         NaN            NaN                        NaN   \n",
      "6628                         NaN            NaN                        NaN   \n",
      "6629                         NaN          120.0                        NaN   \n",
      "6630                         9.0           78.0                       13.0   \n",
      "6631                         NaN            NaN                        NaN   \n",
      "\n",
      "      number_points  number_profiles  length_profiles interpolation_method  \\\n",
      "id                                                                           \n",
      "1               NaN              NaN              NaN                  NaN   \n",
      "2               NaN             10.0              NaN                  NaN   \n",
      "3               NaN              NaN              NaN                  NaN   \n",
      "4               NaN              NaN              NaN                  NaN   \n",
      "5               NaN              NaN              NaN                  NaN   \n",
      "...             ...              ...              ...                  ...   \n",
      "6627           14.0              NaN              NaN                  NaN   \n",
      "6628          217.0              NaN              NaN                  NaN   \n",
      "6629           78.0              NaN              NaN                  NaN   \n",
      "6630           30.0              NaN              NaN               anudem   \n",
      "6631            1.0              NaN              NaN                  NaN   \n",
      "\n",
      "         flag                                            remarks  \n",
      "id                                                                \n",
      "1         NaN                                                NaN  \n",
      "2         NaN                                                NaN  \n",
      "3         NaN                                                NaN  \n",
      "4         NaN                                                NaN  \n",
      "5         NaN                                                NaN  \n",
      "...       ...                                                ...  \n",
      "6627      NaN                                                NaN  \n",
      "6628      NaN  AREA: Sitts et al. 2010 (https://doi.org/10.39...  \n",
      "6629  partial                                                NaN  \n",
      "6630      NaN  LATITUDE/LONGITUDE: FoG 2015 | AREA: Austrian ...  \n",
      "6631      NaN  LATITUDE/LONGITUDE: FoG 2015 | AREA: Austrian ...  \n",
      "\n",
      "[1012 rows x 20 columns]\n",
      "Columns of glacier.csv are:\n",
      "area\n",
      "date\n",
      "external_db\n",
      "external_id\n",
      "flag\n",
      "interpolation_method\n",
      "latitude\n",
      "length_profiles\n",
      "longitude\n",
      "max_date\n",
      "max_thickness\n",
      "max_thickness_uncertainty\n",
      "mean_slope\n",
      "mean_thickness\n",
      "mean_thickness_uncertainty\n",
      "name\n",
      "number_points\n",
      "number_profiles\n",
      "remarks\n",
      "survey_id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "t_path = \"glathida/data/glacier.csv\"\n",
    "df_glacier = pd.read_csv(t_path,index_col=[0])\n",
    "\n",
    "# print(df_glacier)\n",
    "print('Columns of glacier.csv are:')\n",
    "# Use inline to iterate across sorted column values\n",
    "[print(x) for x in df_glacier.columns.sort_values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore the data with visualization**\n",
    "Before making any inference of models with the data, we will start by exploring basic correlations among parameters by plotting. In particular, we will focus on ``mean_thickness``, ``area``, ``mean_slope`` parameters.\n",
    "\n",
    "### d) Remove bad data (1 point)\n",
    "\n",
    "The database may contain Nans and other \"bad\" values (welcome to the data world!). First we will clean the data by removing nans. We are mostly interested in the thickness, area, and slope\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer below \n",
    "NaN_IND = df_glacier[['max_thickness','slope','area'].isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mapping glaciers (10 points)\n",
    "\n",
    "Make a global map of the glaciers. Use either of the tools we learned in class:\n",
    "* Geopandas, DEMs from NetCDFfiles (see chapter 2.4)\n",
    "* Pandas and Plotly (see chapter 2.2). You may need to transform some of the series into log-spaced values for better visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Tif and matplotlib\n",
    "\n",
    "You can use the ``elevation`` data from the DEM seen in class. Download the DEM file (https://www.dropbox.com/s/j5lxhd8uxrtsxko/HYP_50M_SR.tif?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___Tips___: when plotting a image in ``matplotlib`` you need to add information about the physical dimensions of the image. You can calculate the ``bounds``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = (elevation.bounds.left, elevation.bounds.right, \\\n",
    "          elevation.bounds.bottom, elevation.bounds.top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use ``matplotlib.pyplot`` to show the raster image in the background (tips: use ``imshow()``. The raster image in matplotlib can only import one frame and not three (R, G, B) frames. We will first stack the three images together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = elevation.read(1)\n",
    "green = elevation.read(2)\n",
    "blue = elevation.read(3)\n",
    "pix = np.dstack((red, green, blue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Plotly\n",
    "\n",
    "You may use plotly. For improved visibility, transform some of the data into log-spaced. You may add these transformed Series into the Pandas, and use them as input to plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'vscode' # writes as standalone html, \n",
    "# pio.renderers.default = 'iframe' # writes files as standalone html, \n",
    "# pio.renderers.default = 'png' # writes files as standalone html, \n",
    "# try notebook, jupyterlab, png, vscode, iframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlations between data parameters ( 5 points total)\n",
    "\n",
    "Make plots to vizualise the correlation, or lack of, between all three data. Make at least three plots.\n",
    "\n",
    "### a) Basic correlations using Matplotlib (2 points)\n",
    "\n",
    "Make 3 plots using matplotlib to visualize slope, mean_thickness, and area. Use logscale to see the correlatons.\n",
    "\n",
    "__Tips__: \n",
    "* Use the function ``scatter`` to plot the values of mean thickness, mean slope, area, and latitude. \n",
    "* use one of the dataframe columns as a color using the argument ``c``. You can also vary the ``colormap`` using the argument ``cmap``. Help on colormaps can be found here: https://matplotlib.org/stable/tutorials/colors/colormaps.html. Be mindful of Color-Vision Deficient readers and read *Crameri, F., Shephard, G.E. and Heron, P.J., 2020. The misuse of colour in science communication. Nature communications, 11(1), pp.1-10. https://doi.org/10.1038/s41467-020-19160-7* (find it on the class Gdrive). You can add a third \"data\" by choosing a marker color that scales with an other parameter. For instance, try coloring your marker with the ``LAT`` parameter to look at systematic latitudinal trends from the equator to the poles.\n",
    "* Do not forget to adjust fontsize, figure size (at least 10,8), grid, labels with  of the features (example: km). ou may also explore the *logarithmic* correlations by mapping the axis from linear to logarithmic scale ``plt.xscale('log')``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Mean slope vs mean thickness\n",
    "# solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: area vs mean thickness\n",
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) 3D Scatter plot using Plotly (1 point)\n",
    "\n",
    "Use the plotly ``scatter_3d`` plot. Make sure to change the pandas series for log scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Pandas Correlation function (1 point)\n",
    "\n",
    "You may use Pandas functionalities to explore correlation between data. Use the function ``corr`` on the dataframe and the matplotlib function ``matshow`` to plot a heatmap of the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Seaborn Plotting (1 point)\n",
    "\n",
    "Seaborn is a great python package for basic data anlytics. See documentation [here](!https://seaborn.pydata.org/). You can visualize the data by plotting data features against each other and explore visually data correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the basic correlations among the data. Do these correction make sense when you think about the shapes of glaciers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enter text below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Regression (10 points total counted in the next section)\n",
    "You found from basic data visualization that the three parameters ``mean_slope``, ``mean_thickness``, and ``area`` are correlated. It does make physical sense because a *steep* glaciers is likely to be in the high mountains regions, hanging on the mountain walls, and thus be constrained, and conversely, a flat glacier is either at its valley, ocean terminus or on ice sheets.\n",
    "\n",
    "### a) Simple linear regression (2 points)\n",
    "We will now perform a regression between the parameters (or their log!). Linear regressions are models that can be imported from scikit-learn. Log/exp functions in numpy as ``np.log()`` and ``np.exp()``.\n",
    "Remember that a linear regression is finding $a$ and $b$ knowing both $x$ and the data $y$ in $y = Ax +b$. We want to predict ice thickness from a crude estimate of the glacier area.\n",
    "\n",
    "__Tips__: \n",
    "a. make sure that the dimensions are correct and that there is no NaNs and zeros.\n",
    "b. Make sure to inport the scikit learn linear regression function and the error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot of the data and the linear regression your performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Briefly comment on the quality of your fit and a linear regression (1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit looks pretty good, except that there are outliers on the extreme low and high values of mean area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Leave One Out Cross Validation linear regression (1 point)\n",
    "\n",
    "\n",
    "Perform the LOCCV on the ``area`` and ``thickness`` values. Predict the ``thickness`` value knowing a ``area`` value. Use material seen in class. Make a plot of your fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "# solution\n",
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Bootstrapping (1 point)\n",
    "\n",
    "Perform the same analysis but using a bootstrapping technique. Output the mean and standard deviation of the slope. An illustration with a histogram  may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# solution\n",
    "\n",
    "k=100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Predict the thickness of a glacier (2 points)\n",
    "\n",
    "Let assume that you measure a glacier of area 10 km$^2$. Can you use your bootstrap regression framework to provide a distribution of possible values of the ice thickness ? Output the mean and standard deviation of the predicted ice thickness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "k=100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('madrona')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c2df93b363d800c8a9b94963221f1be1d8deaf6a76f83b6b9a486ad05d69583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
